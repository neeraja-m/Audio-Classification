{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import torch\n","import torchvision as tv\n","from torch.utils.data import DataLoader,random_split,Dataset\n","import torch.nn as nn\n","from torchvision import transforms,datasets\n","import torch.optim as optim\n","from torchmetrics import ConfusionMatrix\n","import matplotlib.pyplot as plt\n","import seaborn as sb\n","from torchmetrics.classification import MulticlassAccuracy\n","from torchvision.transforms import Resize,ToTensor,Compose"]},{"cell_type":"markdown","metadata":{},"source":["**Import dataset**"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["# data_path = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/images_original'\n","data_path = 'Data/images_original'\n","genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n","\n","# define dataset split\n","training_size = 0.7\n","validation_size = 0.2\n","testing_size = 0.1\n","\n","# define epochs\n","epoch_a=50\n","epoch_b=100"]},{"cell_type":"markdown","metadata":{},"source":["**Apply transformations**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# initial transformation to find mean and standard deviation of image dataset\n","transform_all_a = transforms.Compose([\n","   transforms.Resize((180, 180)), \n","    transforms.ToTensor()\n","])\n","\n","# find mean and standard deviation of image dataset for normalisation\n","def find_norm_vals(loader):\n","    \n","    # initialise values to 0\n","    pixels = 0\n","    mean = 0.0\n","    stnd = 0.0\n","    \n","    for images, _ in loader:\n","        \n","        # get batch size, number of channels, height, and width of image\n","        batch_size, channel_num, height, width = images.shape\n","        \n","        # calculate number of pixels       \n","        pixels += batch_size * height * width\n","        \n","        # update mean and standard deviation\n","        stnd += images.std(axis=(0, 2, 3)).sum()\n","        mean += images.mean(axis=(0, 2, 3)).sum()\n","        \n","    # calculate mean and standard deviation\n","    stnd /= pixels\n","    mean /= pixels\n","\n","    return mean, stnd\n","\n","gtzan_dataset = datasets.ImageFolder(root=data_path, transform=transform_all_a)\n","\n","\n","loader = DataLoader(gtzan_dataset, batch_size=64, shuffle=True)\n","\n","mean, std = find_norm_vals(loader)\n","\n","print(mean,std)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# transformation for validation and test set\n","transform_all = transforms.Compose([\n","   transforms.Resize((180, 180)), \n","    transforms.ToTensor()\n","])\n","\n","# data augmentation for training set\n","transform_augment= transforms.Compose([\n","    transforms.Resize((180, 180)), #resize image as specified\n","    transforms.RandomHorizontalFlip(),  # flip image horizontally randomly\n","    transforms.RandomRotation(50),       # rotate image up to 50 degrees\n","    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),  # adjust brightness, contrast, saturation, and hue with 0.5 probability\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=mean, std=std)  # normalize image using calculated mean and standard deviation\n","])\n","\n","# define data path and sample size \n","gtzan_dataset = datasets.ImageFolder(root=data_path)\n","sample_num = len(gtzan_dataset)\n","\n","train_samples = int(training_size * sample_num)\n","val_samples = int(validation_size * sample_num)\n","test_samples = sample_num - train_samples - val_samples\n","\n","# define seed for reproducibility \n","seed = 2\n","torch.manual_seed(seed)\n","\n","# split data\n","train_data, val_data, test_data = random_split(gtzan_dataset, [train_samples, val_samples, test_samples])\n","\n","# apply transformations \n","train_data.dataset.transform = transform_augment\n","val_data.dataset.transform = transform_all\n","test_data.dataset.transform = transform_all\n","\n","# load data using DataLoader\n","train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n","\n","# flatten input\n","# itr=iter(train_loader)\n","# imgs,labels=next(itr)\n","# input=torch.flatten(imgs,start_dim=1)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Net1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","# define parameters\n","input_size=180*180*3\n","hidden_size1=128\n","hidden_size2=64\n","output_size=10\n","\n","# define model \n","class Net1(nn.Module): \n","  def __init__(self):\n","    super(Net1, self).__init__()\n","    self.net=nn.Sequential(nn.Flatten(start_dim=1),\n","                            nn.Linear(input_size,hidden_size1),\n","                            nn.ReLU(),\n","                            nn.Linear(hidden_size1,hidden_size2),\n","                            nn.ReLU(),\n","                            nn.Linear(hidden_size2,output_size))\n","                          \n","  def forward(self,x):\n"," \n","    return self.net(x)\n","\n","# move model to gpu\n","model=Net1()\n","model.to('cuda') \n","\n","# define learning rate as 0.0001 and optimiser as Adam\n","lr=0.0001 \n","optimizer=optim.Adam(model.parameters(),lr=lr)"]},{"cell_type":"markdown","metadata":{},"source":["# Net2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# define model\n","class Net2(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        #(3,180,180)\n","        self.conv1=nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,padding=\"same\")\n","        #(64,180,180)\n","        self.conv2=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=\"same\")\n","        #(128,180,180)\n","        self.pool1=nn.MaxPool2d(2)\n","        #(128,90,90)\n","        self.conv3=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=\"same\")\n","        #(256,90,90)\n","        self.conv4=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,padding=\"same\")\n","        #(256,90,90)\n","        self.pool2=nn.MaxPool2d(2)\n","        #(256,45,45)\n","        self.relu=nn.ReLU()\n","        self.fc1=nn.Linear(in_features=256*45*45,out_features=256)\n","        self.fc2=nn.Linear(in_features=256,out_features=10)\n","        self.do1 = nn.Dropout(p=0.8)\n","        self.bn = nn.BatchNorm2d(256) \n","        \n","    def forward(self,x):\n","        x=self.conv1(x)\n","        x=self.relu(x)\n","        x=self.conv2(x)\n","        x=self.relu(x)\n","        x=self.pool1(x)\n","        x=self.conv3(x)\n","        x=self.relu(x)\n","        x=self.conv4(x)\n","        x=self.relu(x)\n","        x=self.pool2(x)\n","        x=x.view(x.size()[0],-1)\n","        x=self.fc1(x)\n","        x=self.relu(x)\n","#         x=self.do1(x)\n","        x=self.fc2(x)\n","        return x\n","\n","# move model to gpu\n","model=Net2()\n","model.to('cuda')\n","\n","# define learning rate as 0.0001 and optimiser as Adam\n","lr=0.0001\n","optimizer=optim.Adam(model.parameters(),lr=lr)"]},{"cell_type":"markdown","metadata":{},"source":["# Net3"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# define model\n","class Net3(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        #(3,180,180)\n","        self.conv1=nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,padding=\"same\")\n","        #(64,180,180)\n","        self.conv2=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=\"same\")\n","        #(128,180,180)\n","        self.pool1=nn.MaxPool2d(2)\n","        #(128,90,90)\n","        self.conv3=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=\"same\")\n","        #(256,90,90)\n","        self.conv4=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,padding=\"same\")\n","        #(256,90,90)\n","        self.pool2=nn.MaxPool2d(2)\n","        #(256,45,45)\n","        self.relu=nn.ReLU()\n","        self.fc1=nn.Linear(in_features=256*45*45,out_features=256)\n","        self.fc2=nn.Linear(in_features=256,out_features=10)\n","        self.do1 = nn.Dropout(p=0.8)\n","        self.bn = nn.BatchNorm2d(256) \n","        \n","    def forward(self,x):\n","        x=self.conv1(x)\n","        x=self.relu(x)\n","        x=self.conv2(x)\n","        x=self.relu(x)\n","        x=self.pool1(x)\n","        x=self.conv3(x)\n","        x=self.relu(x)\n","        x= self.bn(x) # addition of batch normalisation layer\n","        x=self.conv4(x)\n","        x=self.relu(x)\n","        x=self.pool2(x)\n","        x=x.view(x.size()[0],-1)\n","        x=self.fc1(x)\n","        x=self.relu(x)\n","#         x=self.do1(x)\n","        x=self.fc2(x)\n","        return x\n","    \n","# move model to gpu\n","model=Net3()\n","model.to('cuda')\n","\n","# define learning rate as 0.0001 and optimiser as Adam\n","lr=0.0001\n","optimizer=optim.Adam(model.parameters(),lr=lr)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Net4"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# define model \n","class Net4(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        #(3,180,180)\n","        self.conv1=nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,padding=\"same\")\n","        #(64,180,180)\n","        self.conv2=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=\"same\")\n","        #(128,180,180)\n","        self.pool1=nn.MaxPool2d(2)\n","        #(128,90,90)\n","        self.conv3=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=\"same\")\n","        #(256,90,90)\n","        self.conv4=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,padding=\"same\")\n","        #(256,90,90)\n","        self.pool2=nn.MaxPool2d(2)\n","        #(256,45,45)\n","        self.relu=nn.ReLU()\n","        self.fc1=nn.Linear(in_features=256*45*45,out_features=256)\n","        self.fc2=nn.Linear(in_features=256,out_features=10)\n","        self.do1 = nn.Dropout(p=0.8)\n","        self.bn = nn.BatchNorm2d(256) \n","        \n","    def forward(self,x):\n","        x=self.conv1(x)\n","        x=self.relu(x)\n","        x=self.conv2(x)\n","        x=self.relu(x)\n","        x=self.pool1(x)\n","        x=self.conv3(x)\n","        x=self.relu(x)\n","        x= self.bn(x)\n","        x=self.conv4(x)\n","        x=self.relu(x)\n","        x=self.pool2(x)\n","        x=x.view(x.size()[0],-1)\n","        x=self.fc1(x)\n","        x=self.relu(x)\n","#         x=self.do1(x)\n","        x=self.fc2(x)\n","        return x\n","    \n","# move model to gpu    \n","model=Net4()\n","model.to('cuda')\n","\n","# define learning rate as 0.0001 and optimiser as RMSprop\n","lr=0.0001\n","optimizer = optim.RMSprop(model.parameters(), lr=lr,alpha=0.99)\n"]},{"cell_type":"markdown","metadata":{},"source":["**Train model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#track running model\n","print(\"Running model:\", model.__class__.__name__) \n","\n","# define loss function\n","loss_fn=nn.CrossEntropyLoss() \n","\n","# switch in epoch variable as needed\n","epochs = epoch_a\n","# epochs = epoch_b\n","\n","# run training loop \n","for epoch in range(epochs):\n","    \n","    # initialise values to 0\n","    running_loss = 0.0 \n","    correct =0\n","    total =0\n","    \n","    for images, labels in train_loader:\n","        images, labels = images.to('cuda'), labels.to('cuda')  # move data to gpu\n","        optimizer.zero_grad()  # reset gradients\n","        \n","        # complete forward pass\n","        outputs = model(images)  \n","        loss = loss_fn(outputs, labels) \n","        \n","        # complete backward pass\n","        loss.backward()  \n","        optimizer.step()  \n","        \n","        # update loss     \n","        running_loss += loss.item() * images.size(0)  \n","        \n","        # update accuracy\n","#         _, predicted = torch.max(outputs, 1) \n","#         correct += (predicted == labels).float().sum()\n","\n","    \n","#     accuracy = 100 * correct / len(train_loader.dataset)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}')\n","#     print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy:{accuracy:.2f} ')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["**Evaluate model performance**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# define confusion matrix with 10 classes\n","con_mat=ConfusionMatrix(task='multiclass',num_classes=10).cuda()\n","\n","# evaluate model accuracy \n","def evaluate(loader,model): \n","    \n","    # initialise total count  \n","    total=0\n","    \n","    for imgs,labels in loader:\n","        # move data to gpu    \n","        imgs=imgs.cuda() \n","        labels=labels.cuda() \n","        outputs=model(imgs.cuda()) \n","        \n","        # predicted output        \n","        _,pred=torch.max(outputs,dim=1) \n","        \n","        # update total correct count and update confusion matrix       \n","        total+=(pred==labels).sum() \n","        con_mat.update(pred,labels)\n","\n","    return total.item(),(total/len(loader.dataset)).item()\n","\n","nitems,accuracy=evaluate(test_loader,model) \n","print(\"Test accuracy={:.4f}\".format(accuracy))\n","\n","# output confusion matrix\n","x=con_mat.compute().cpu().numpy() \n","plt.figure(figsize=(10,7)) \n","sb.heatmap(x,annot=True,fmt=\".0f\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":568973,"sourceId":1032238,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
